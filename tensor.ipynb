{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFFm/UdaLgy71/7QKHdgxR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rainwoorimforest/pytorch-study/blob/main/tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-uv8Y66O9E5b"
      },
      "outputs": [],
      "source": [
        "import numpy as nvep"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Type\n",
        "* 스칼라\n",
        "* 벡터\n",
        "* 행렬\n",
        "* 텐서"
      ],
      "metadata": {
        "id": "rvztCS1R_9Wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = np.array(3)\n",
        "print(f'Scalar value: {scalar}')\n",
        "print(f'Rank: {scalar.ndim}, Shape: {scalar.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZhuX_6C9IZ7",
        "outputId": "68d18ec0-3d90-4904-cde7-6d35ed52c134"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scalar value: 3\n",
            "Rank: 0, Shape: ()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector = np. array([0,1,2,3,4,5])\n",
        "print(f'vector value: {vector}')\n",
        "print(f'vector rank: {vector.ndim}, vector shape: {vector.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqDrGFl99VEa",
        "outputId": "ef73575a-f8ea-41c7-98d1-615075789a85"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vector value: [0 1 2 3 4 5]\n",
            "vector rank: 1, vector shape: (6,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 행렬\n",
        "matrix = np.array([[0,1,2],[3,4,5],[6,7,8]])\n",
        "print(f'Matrix values: \\n {matrix}')\n",
        "print(f'Rank: {matrix.ndim}, Shape: {matrix.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKd4TW-b9mpn",
        "outputId": "215af650-2a1e-4892-ae6e-81ab3f6d3ce9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix values: \n",
            " [[0 1 2]\n",
            " [3 4 5]\n",
            " [6 7 8]]\n",
            "Rank: 2, Shape: (3, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tensor\n",
        "rank가 여러개인 것을 많이 다루는데,\n",
        "보통 가장 앞에 있는 인덱스를 batch로 받는다.\n",
        "* 일반적인 예시: (batch, width, height)\n",
        "* **(일반적으로)가장 앞에 있는 첫번째 차원은 batch라 생각하고 , 그 뒤에 나머지 rank개의 텐서를 진짜 데이터의 형식이라 생각하자!**\n",
        "\n",
        "\n",
        "deep netural network도 마찬가지로 수많은 파라미터를 가지고 있다. 4만장 이미지를 한꺼번에 인간이 볼 수 없듯이 컴퓨터도 메모리 안에 올릴 수 있는 메모리가 한정적이므로 이를 데이터를 잘라서 input으로 넣는다. 이를 mini batch라한다.\n",
        "\n",
        "✔️batch = 2, width = 5, height = 5\n",
        "➡️몇만장 되는 5x5(데이터 형식) 이미지를 2장씩 가져와서 처리할거다,"
      ],
      "metadata": {
        "id": "WKql5Eo--YEa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ 2. 직접 예제로 확인\n",
        "🔸 예: 4장, 2×3 행렬 → shape = (4, 2, 3)"
      ],
      "metadata": {
        "id": "1E1mgErQN4kJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = torch.tensor([\n",
        "    [[1,2,3],[4,5,6]],\n",
        "\n",
        "    [[1,2,3],[4,5,6]],\n",
        "\n",
        "    [[1,2,3],[4,5,6]],\n",
        "\n",
        "    [[1,2,3],[4,5,6]]\n",
        "\n",
        "])\n",
        "\n",
        "print(example.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0wqWJ4EN3rQ",
        "outputId": "8790f44b-defe-415e-ee50-8013ebde3394"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = np.array([[[0,1],[4,5]], [[6,7],[7,8]], [[10,11],[2,4]]])\n",
        "print(f'Tensor values: \\n{tensor}')\n",
        "print(f'Rank: {tensor.ndim}, Shape: {tensor.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C-i4iNc-AZ8",
        "outputId": "49abad55-f5bb-483b-b033-d43f4e3753ea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor values: \n",
            "[[[ 0  1]\n",
            "  [ 4  5]]\n",
            "\n",
            " [[ 6  7]\n",
            "  [ 7  8]]\n",
            "\n",
            " [[10 11]\n",
            "  [ 2  4]]]\n",
            "Rank: 3, Shape: (3, 2, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch - numpy\n",
        "\n",
        "* 앞에서는 numpy로 tensor를 만들었고,\n",
        "* 지금부터는 torch로 tensor를 바로 만들어보자\n",
        "\n",
        "짚어볼거는 각각의 인덱스를 보자.\n",
        "tensor[0]은 행을 말하는 것!!\n"
      ],
      "metadata": {
        "id": "87DRXSE8AEqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "t = torch.tensor([[0,1,2],[3,4,5],[6,7,8]])\n",
        "print(f'Tensor values: \\n{t}')\n",
        "print(f'Rank: {t.dim()}, Shape: {t.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iUY-UKq_s9x",
        "outputId": "a8e45539-4e27-420b-8d09-b950a0606b94"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "Rank: 2, Shape: torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f't[0]: {t[0]}')\n",
        "print(f't[-1]: {t[-1]}')\n",
        "print(f't[-2]: {t[-2]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3I4k70bBBfE",
        "outputId": "78fe6c6b-c42e-4d2a-b390-79ebfbeefe84"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t[0]: tensor([0, 1, 2])\n",
            "t[-1]: tensor([6, 7, 8])\n",
            "t[-2]: tensor([3, 4, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f't[:1]: {t[:1]}')\n",
        "print(f't[1:2]: {t[1:2]}')\n",
        "print(f't[2:]: {t[2:]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST4j8zOcBK4a",
        "outputId": "2ab44aa1-136d-494b-96c7-c92401aa028b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t[:1]: tensor([[0, 1, 2]])\n",
            "t[1:2]: tensor([[3, 4, 5]])\n",
            "t[2:]: tensor([[6, 7, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tensor 연산\n",
        "* Broadcasting: 덧셈, 뺏셈 시에는 차원의 수가 보통 같아야 하는데, pytorch에서는 자동적으로 broadingcasting지원해서 차원 수가 지 않아도 알아서 계산해준다.\n",
        "-> 텐서 연산에는 오류가 안나고 학습이 돌아가기 때문에 이건 항상 확인해야한다\n",
        "\n",
        "* same shape\n",
        "\n",
        "---\n",
        "* vector + scalar"
      ],
      "metadata": {
        "id": "rHySI46xBsN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.tensor([1,4]) + torch.tensor([2,-1])) #same shape\n",
        "print(torch.tensor([1,4]) + torch.tensor([-1])) # Broadcasting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNj_r2_iBirK",
        "outputId": "56bda4cb-5c8b-40db-a202-2d84be5c977d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 3])\n",
            "tensor([0, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.tensor([1,2]) + torch.tensor([[3],[4]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqIj2-hpB7nJ",
        "outputId": "1a44f197-5a08-4807-ac77-c03519e438bd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4, 5],\n",
            "        [5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr_1 = np.array(\n",
        "    [1,2]\n",
        ")\n",
        "\n",
        "arr_2 = np.array(\n",
        "    [\n",
        "        [3], [4]\n",
        "    ]\n",
        ")\n",
        "arr_new = arr_1 + arr_2\n",
        "\n",
        "print(arr_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dfgF40kCphS",
        "outputId": "b3807474-0a9c-495f-bde2-35fd17865d3a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 5]\n",
            " [5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = torch.tensor([[1,2],[3,4]])\n",
        "m2 = torch.tensor([[1],[2]])\n",
        "print(m1.shape, m2.shape)\n",
        "print(f'{m1}')\n",
        "print(f'{m1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljZVRLkbDTIV",
        "outputId": "2c049c3f-c13f-4b5b-8b8d-d350dd44e7aa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2]) torch.Size([2, 1])\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 행렬 곱\n",
        "# layer하나 지날때마다 행렬곱: 한 레이어에서 다음 레이어로 넘어갈 때, 입력 벡터에 가중치를 곱해주는 연산.\n",
        "\n",
        "# 이 연산은 **정보를 선형 변환(linear transformation)**하는 역할을 함.\n",
        "print(f'Matrix multiplication 곱셈: \\n{m1.matmul(m2)} \\n{m1@m2}') # matmul 쓰기 귀찮으면 @으로해도 무방"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCDIGz_HD65f",
        "outputId": "2be5fe1e-7f3a-4b89-9152-8c316056af6b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix multiplication 곱셈: \n",
            "tensor([[ 5],\n",
            "        [11]]) \n",
            "tensor([[ 5],\n",
            "        [11]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hadamard product: 원소끼리 곱\n",
        "# attention mask할때 자주 쓰임 ➡️ 주로 **정보를 유지하거나 제거하는 역할 (필터링)**으로 사용됨.\n",
        "print(f'Elementwise multiplication: \\n{m1.mul(m2)} \\n{m1*m2}') # mul 쓰기 귀찮으면 *으로해도 무방"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRPDsTS0EKEN",
        "outputId": "dda99318-4f36-4716-c427-6aa542ca1338"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elementwise multiplication: \n",
            "tensor([[1, 2],\n",
            "        [6, 8]]) \n",
            "tensor([[1, 2],\n",
            "        [6, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (추가)주 사용처:\n",
        "# Attention mask,\n",
        "\n",
        "# Self-attention score와 mask를 곱해서 특정 위치 무시,\n",
        "\n",
        "# 게이트 연산 (예: LSTM, GRU)\n",
        "\n",
        "# Residual 연결에서 scaling 등)\n",
        "# 예: attention score와 mask를 곱해서 마스킹\n",
        "scores = torch.tensor([\n",
        "    [0.8, 0.1],\n",
        "    [0.5, 0.9]\n",
        "])\n",
        "\n",
        "scores = torch.randn(8, 8)  # (query_len, key_len)\n",
        "mask = torch.tensor([\n",
        "    [1, 1, 0, 0, 1, 1, 0, 1]\n",
        "], dtype=torch.float32)  # 특정 위치를 무시하려는 mask\n",
        "\n",
        "masked_scores = scores * mask  # 원소별 곱\n",
        "\n",
        "print(masked_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3clEAot1IBIQ",
        "outputId": "142371b1-bf9c-400b-d8a3-f62fa8d93bb8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.6733, -1.4621,  0.0000, -0.0000,  0.2063, -0.2882, -0.0000, -0.1782],\n",
            "        [-1.5941, -1.2985, -0.0000,  0.0000,  0.5634, -0.3931, -0.0000, -0.3929],\n",
            "        [ 0.6646, -1.5730,  0.0000,  0.0000, -0.8627, -0.5128,  0.0000,  0.3383],\n",
            "        [ 1.5517, -0.4883,  0.0000,  0.0000, -0.2312, -0.3795, -0.0000, -0.9935],\n",
            "        [ 0.1542, -0.0982, -0.0000, -0.0000,  0.5292, -0.1590, -0.0000, -0.9541],\n",
            "        [ 0.9866, -0.6249, -0.0000, -0.0000,  0.6068,  0.0539, -0.0000,  1.8513],\n",
            "        [-1.1873, -0.6033,  0.0000,  0.0000, -1.0674, -0.8804, -0.0000,  0.0982],\n",
            "        [-1.2316,  0.4669,  0.0000,  0.0000, -1.7576, -1.4969,  0.0000,  1.4770]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "scores =\n",
        "[[0.8, 0.1],    ← query 0\n",
        " [0.5, 0.9]]    ← query 1\n",
        "        ↑\n",
        "      key 0, key 1\n",
        "\n",
        "# 열 기준(dim=0) 최대값 비교:\n",
        "\n",
        "Column 0: max(0.8, 0.5) → 0.8 → index 0  \n",
        "Column 1: max(0.1, 0.9) → 0.9 → index 1\n",
        "\n",
        "# 출력 결과:\n",
        "\n",
        "Max values (dim=0): tensor([0.8, 0.9])\n",
        "Argmax indices (dim=0): tensor([0, 1])\n",
        "\n",
        "# 🤔 현실적인 의미 (self-attention 시나리오로 본다면)\n",
        "scores[i][j]는 query i가 key j를 얼마나 주목하는지를 의미\n",
        "\n",
        "max(dim=0)는 각 key가 어떤 query로부터 가장 크게 주목받는지를 본다고 해석 가능\n"
      ],
      "metadata": {
        "id": "7Hm0pvBBIrMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "t = torch.tensor([[1.,2.],[3.,4.]])\n",
        "print(t)\n",
        "print(t.mean())\n",
        "print(t.mean(dim=0)) # dim 행축으로 연산하겠다. 열 요소들끼리 연산. 즉, dim=0은 1과 3의 평균\n",
        "print(t.mean(dim=1))# dim 열축으로 연산하겠다.행 요소들끼리 연산. 즉, dim=1은 2과 4의 평균,\n",
        "print(t.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tkx4dYVqEYwt",
        "outputId": "d7b28cc9-5def-454e-9cd7-29b80637fa9e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "tensor(2.5000)\n",
            "tensor([2., 3.])\n",
            "tensor([1.5000, 3.5000])\n",
            "tensor(1.2910)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t.sum())\n",
        "print(t.sum(dim=0))\n",
        "print(t.sum(dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D0pX9sVFTYa",
        "outputId": "399a316b-a012-439a-99dd-bb884c7c04d2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.)\n",
            "tensor([4., 6.])\n",
            "tensor([3., 7.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-HuVaL4F7_8",
        "outputId": "6d81dcea-fa40-43f3-acb5-cdcc9f5f135c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "t = torch.tensor([\n",
        "    [1., 2.],\n",
        "    [3., 4.]\n",
        "])\n",
        "\n",
        "values  = tensor([3., 4.])   # 각 열(column)에서 최대값\n",
        "indices = tensor([1, 1])     # 각 열에서 최대값이 있는 행(row)의 인덱스\n",
        "\n",
        "\n",
        "values, indices = t.max(dim=0) # 🔍 dim=0(행축으로)→ 열 방향으로 연산, 각 column의 값들을 비교:\n",
        "\n"
      ],
      "metadata": {
        "id": "kJP5DCHEHKNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Column index | 비교 값들 | Max 값 | Argmax (행 인덱스) |\n",
        "| ------------ | ----- | ----- | -------------- |\n",
        "| 0            | 1, 3  | **3** | 1              |\n",
        "| 1            | 2, 4  | **4** | 1              |\n"
      ],
      "metadata": {
        "id": "RBRq3mzhHO1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Max: {t.max(dim=0)[0]}, Argmax: {t.max(dim=0)[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQLhiJDnGA8v",
        "outputId": "6f850a5d-a871-4321-df1b-77f590618fd7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max: tensor([3., 4.]), Argmax: tensor([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tensor 연산2\n",
        "\n",
        "* 2장짜리 입체적으로 있던 것이 위아래 붙어 3x4 나오도록..\n",
        "* 2장짜리 입체적으로 있던 것이 1*3으로만 살려 뒤로 붙어나오도록"
      ],
      "metadata": {
        "id": "pYjH5N7aJDTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### view"
      ],
      "metadata": {
        "id": "pE2UF8k_LZVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#view(기존에는 reshape)\n",
        "# -1: 계산하기 귀찮으니까 남은것은 pytorch가 알아서 정리하라는 일종의 ... 머시기\n",
        "\n",
        "t = torch.tensor([[[0,1,2],[3,4,5]],[[6,7,8],[9,10,11]]])\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sI2jyZFGKRW",
        "outputId": "b6823e4a-8a21-4b20-a0e0-44b3a7076a7a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0,  1,  2],\n",
            "         [ 3,  4,  5]],\n",
            "\n",
            "        [[ 6,  7,  8],\n",
            "         [ 9, 10, 11]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t.shape) # 2x3이미지가 2장짜리 겹쳐져있는 것"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNBfqYS8Kh5X",
        "outputId": "4448e84c-056d-4755-ce6f-95dc61f9236d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t.view([-1,3])) # 열 3개만 살리고 알아서 계산 : 위아래\n",
        "print(t.view([-1,3]).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY8sVjPkKpz5",
        "outputId": "ae412893-b3fe-4c33-fbfd-2dae2518eb15"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  7,  8],\n",
            "        [ 9, 10, 11]])\n",
            "torch.Size([4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t.view([-1,1,3])) # 행 1 열 3개만 살리고 알아서 계산: 뒤로 보내\n",
        "print(t.view([-1,1,3]).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC3DkTDKK2p7",
        "outputId": "c64f74c7-2f6b-4cdf-89ca-b3769c25c525"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0,  1,  2]],\n",
            "\n",
            "        [[ 3,  4,  5]],\n",
            "\n",
            "        [[ 6,  7,  8]],\n",
            "\n",
            "        [[ 9, 10, 11]]])\n",
            "torch.Size([4, 1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ 이처럼 reshape하면서 내가 input으로 넣는 데이터의 shape를 항상 확인하는 습관을 가지자.\n"
      ],
      "metadata": {
        "id": "nvBnXq49LQ52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### squeeze"
      ],
      "metadata": {
        "id": "yGAg0EfyLbBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[0],[1],[2],[3]])\n",
        "print(t)\n",
        "print(t.shape)\n",
        "\n",
        "print(t.squeeze())\n",
        "print(t.squeeze().shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vGDSefiLOai",
        "outputId": "1420c090-8c71-4b10-b195-7c5f4245fef6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0],\n",
            "        [1],\n",
            "        [2],\n",
            "        [3]])\n",
            "torch.Size([4, 1])\n",
            "tensor([0, 1, 2, 3])\n",
            "torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "t = torch.tensor([\n",
        "    [[1., 2., 3.]],\n",
        "    [[4., 5., 6.]],\n",
        "    [[7., 8., 9.]],\n",
        "    [[10., 11., 12.]]\n",
        "])\n",
        "\n",
        "print(t.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wCdxW_FLt4n",
        "outputId": "9db6dcae-bac2-4c43-a85a-313b783d961e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenation\n",
        "t1 = torch.tensor([[1,2],[3,4]])\n",
        "t2 = torch.tensor([[5,6],[7,8]])\n",
        "print(t1)\n",
        "print(t2)\n",
        "print(torch.cat([t1,t2], dim=0)) # 행축으로 계산 4x2\n",
        "print(torch.cat([t1,t2], dim=1)) # 열축으로 계산 2x4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV2Kt-ZpMBaM",
        "outputId": "f6736d78-b95a-4df0-d872-1f7a34b43ddf"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor([[5, 6],\n",
            "        [7, 8]])\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6],\n",
            "        [7, 8]])\n",
            "tensor([[1, 2, 5, 6],\n",
            "        [3, 4, 7, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stacking\n",
        "t1 = torch.tensor([1,4])\n",
        "t2 = torch.tensor([2,5])\n",
        "t3 = torch.tensor([3,6])\n",
        "\n",
        "print(torch.stack([t1,t2,t3])) # 3x2\n",
        "print(torch.stack([t1,t2,t3], dim=1)) # 2x3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg4U4cBdM9WO",
        "outputId": "fd82edee-6bb8-454f-a268-0554284a7cb1"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ones and zeros\n",
        "t = torch.tensor([[3,2,-1],[3,2,0]])\n",
        "print(t.shape)\n",
        "\n",
        "print(torch.ones_like(t))\n",
        "print(torch.zeros_like(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgcxlETGNiSy",
        "outputId": "a0dbaa70-c7ac-4a9a-c420-59ad8f9f4e61"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n",
            "tensor([[1, 1, 1],\n",
            "        [1, 1, 1]])\n",
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In-place Operation\n",
        "t = torch.tensor([[1.,2.], [3.,4.]])\n",
        "print(t.mul(2.))\n",
        "print(t)\n",
        "print(t.mul_(2.)) # _ 붙이면 n-place Operation작동해서 연산 결과가 original 변수에 저장\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7turg8zOeaU",
        "outputId": "f1b329eb-f674-43a3-d7a7-d585081f1cf2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n",
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "train_dataset = datasets.MNIST(\n",
        "    root = './data', train=True, transform = transforms.ToTensor(), download = True)\n",
        "\n",
        "test_dataset = datasets.MNIST(\n",
        "    root = './data', train=False, transform = transforms.ToTensor(), download = True)\n"
      ],
      "metadata": {
        "id": "D0NAJijbPgCU"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_dataset[0] # sample\n",
        "\n",
        "print(image.shape) # 1장짜리 w*h 이미지\n",
        "print(label)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "yQUuZDTuQ0D2",
        "outputId": "d127159b-6598-4d74-ae09-0e3fe262d85b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}